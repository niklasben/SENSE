<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="xsl/oai2.xsl"?><OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2014-10-15T06:53:50Z</responseDate>
  <request verb="GetRecord" metadataPrefix="oai_dc" identifier="oai:kobv.de-opus4-tuberlin:2076">http://opus4.kobv.de/opus4-tuberlin/oai</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:kobv.de-opus4-tuberlin:2076</identifier>
        <datestamp>2013-07-01</datestamp>
        <setSpec>doc-type:doctoralthesis</setSpec>
        <setSpec>bibliography:false</setSpec>
        <setSpec>ddc</setSpec>
        <setSpec>ddc:004</setSpec>
      </header>
      <metadata>
        <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
          <dc:title xml:lang="eng">The Robust 3-D Sceneflow : Generalized Video-based 3-D Analysis using Robust Camera and Scene Geometry Estimations</dc:title>
          <dc:title xml:lang="deu">Der robuste 3D-Szenenfluss: Allgemeine Video-basierte 3-D-Analyse mit Robuster Kamerageometrie und Szenengeometrie Schätzungen</dc:title>
          <dc:creator>Kim, Jang Heon</dc:creator>
          <dc:subject>ddc:004</dc:subject>
          <dc:description xml:lang="deu">Recovering 3-D information from several 2-D images is one of the most important topics in computer vision. There are a lot of applications in different areas such as TV contents, games, medical applications, robot navigation and special effects, etc. Multi-stereo and Structure-from-Motion methods aim to recover the 3-D camera pose and scene structure for a rigid scene from an uncalibrated sequence of 2-D images. The 3-D camera pose can be estimated as the principle projection ray for a camera observing a rigid scene. The line of principal ray defines the collineation of all viewpoints observing the same scene. However, the projective camera geometry is involved in a number of distorted images for a Euclidean geometric object since the projection is a non-metrical form of geometry. This means that the collineation of projective ray is not always satisfied in metrically distorted pixels in the viewpoints, and the distortion is the image form of divergent rays on the 3-D surfaces. The estimation of dense scene geometry is a process to recover the metric geometry and to adjust the global ray projection passing through each 2-D image point to a 3-D scene point on real object surfaces. The generalization of 3-D video analysis depends on the density and robustness of the scene geometry estimation. In this dissertation, the 3-D sceneflow method that analyzes jointly stereo and motion is proposed for retrieving the camera geometry and reconstructing dense scene geometry accurately. The stereo viewpoints provide more robust 3-D information against noises, and the viewpoints of the camera motion increase the spatial density of the 3-D information. This method utilizes a brightness-invariance constraint that a set of spatio-temporal correspondences do not change for a 3-D scene point. Due to physical imperfections in the imaging sensors and bad locations of detected features and false matches, image data contain a lot of outliers. A unified scheme of robust estimation is proposed to eliminate outliers both from feature-based camera geometry estimates and dense scene geometry estimates. With a robust error weight, the error distribution of estimates can be restricted in a smoothly invariant support region, and the anisotropic diffusion regularization efficiently eliminates outliers in the regional structure. Finally, the structure-preserving dense 3-D sceneflow is obtained from stereo-motion sequences for a 3-D natural scene.</dc:description>
          <dc:description xml:lang="eng">Die Gewinnung der 3D-Information aus unterschiedlichen 2D-Bildern gehört zu den wichtigsten Forschungsthemen der Computer Vision. Dieses Feld hat eine Vielzahl von Anwendungen in den verschiedensten Bereichen, z. B. bei der Generierung von TV-Inhalten, für Videospiele, im medizinischen Bereich, bei der Roboternavigation und für Spezialeffekte im Kino. Dabei gibt es bereits eine Menge Forschungsarbeiten zum Thema, welche allgemein zum Ziel haben, die 3D-Koordinaten der Kamera und die Szenenstruktur für statische Inhalte aus unkalibrierten 2D-Bilder bestimmen, dies zum Beispiel mittels des Multi-Stereo-Ansatzes oder durch die Structure-from-Motion-Analyse. Die 3D-Kameraposition kann mittels der Hauptprojektionsachse einer Kameraaufnahme für eine statische Szene geschätzt werden. Diese Achse definiert die Collineation der Blickpunkte, welche die gleiche Szene beobachten. Allerdings verursacht die projektive Kamerageometrie bestimmte Bildverzerrungen für Euklidische Objekte, da sie selbst keine metrische Abbildung darstellt. Dies hat zur Folge, dass die Collineation von Strahlen nicht mehr für metrisch verzerrte Pixel erfüllt ist, wobei dann die Verzerrung selber die Abbildung divergenter Strahlen darstellt. Die Schätzung der dichten Szenengeometrie ist ein Prozess, mit dessen Hilfe einerseits die metrische Geometrie wiedergewonnen wird und andererseits die globale Projektion so adjustiert wird, dass jeder Bildpunkt bei der Projektion in den 3D-Raum auf die echte Objektoberfläche abgebildet wird. Die Verallgemeinerung der 3D-Videoanalyse hängt dabei von der Dichte und Robustheit der Schätzung der 3D-Szenengeometrie ab. In dieser Dissertation wird zur Ermittlung der Kamerageometrie und für die Rekonstruktion der dichten Szenengeometrie die Methode des dreidimensionalen Szenenflusses vorgeschlagen, welche die Stereo- und Bewegungsinformationen gemeinsam analysiert. Hinsichtlich verschiedenartiger Rauschstörungen bieten Stereoanordnungen robustere 3D-Informationen, hingegen erhöhen die Blickpunkte einer sich bewegenden Kamera die räumliche Kameradichte. Die vorgeschlagene Methode geht dabei von der Helligkeitsinvarianzbedingung aus, welche besagt, dass raum-zeitliche Korrespondenzen zwischen Abbildungen eines 3D-Szenenpunktes unveränderlich sind. Aufgrund physikalischer Ungenauigkeiten der optischen Sensoren, schlechter Lokalisierungen von Merkmalspunkten und sich daraus ergebender fehlerhafter Punktzuordnungen enthalten die Bilddaten eine Menge von Ausreißern. Deshalb wird hier ein vereinheitlichter Ansatz zur robusten Schätzung und Eliminierung der Ausreißer bei gleichzeitiger Bestimmung der Kamera-geometrie sowie der dichten Szenengeometrie verfolgt. Mittels einer robusten Fehlerwichtung, bei der die Fehlerverteilung der Schätzungen auf einen näherungsweise invarianten Bereich begrenzt wird, und durch Verwendung einer auf anisotroper Diffusion basierender Regularisierung werden die Ausreißer in der regionalen Struktur effizient eliminiert. Letztendlich kann der dichten 3D-Szenenfluss aus Stereobildsequenzen mit natürlichen Inhalten gewonnen werden.</dc:description>
          <dc:date>2009-03-18</dc:date>
          <dc:type>doctoralthesis</dc:type>
          <dc:type>doc-type:doctoralthesis</dc:type>
          <dc:format>application/zip</dc:format>
          <dc:format>application/pdf</dc:format>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/frontdoor/index/index/docId/2076</dc:identifier>
          <dc:identifier>urn:nbn:de:kobv:83-opus-21739</dc:identifier>
          <dc:identifier>http://nbn-resolving.de/urn/resolver.pl?urn:nbn:de:kobv:83-opus-21739</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/2076/original_kim_jangheon.zip</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/2076/kim_jangheon.pdf</dc:identifier>
          <dc:language>eng</dc:language>
          <dc:rights> CC BY-NC-ND: Creative Commons-Lizenz: Namensnennung, nicht kommerziell, keine Bearbeitung</dc:rights>
        </oai_dc:dc>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
