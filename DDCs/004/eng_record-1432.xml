<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="xsl/oai2.xsl"?><OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2014-10-15T06:51:04Z</responseDate>
  <request verb="GetRecord" metadataPrefix="oai_dc" identifier="oai:kobv.de-opus4-tuberlin:1432">http://opus4.kobv.de/opus4-tuberlin/oai</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:kobv.de-opus4-tuberlin:1432</identifier>
        <datestamp>2013-07-01</datestamp>
        <setSpec>doc-type:doctoralthesis</setSpec>
        <setSpec>bibliography:false</setSpec>
        <setSpec>ddc</setSpec>
        <setSpec>ddc:004</setSpec>
      </header>
      <metadata>
        <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
          <dc:title xml:lang="eng">Unsupervised Learning Methods for Statistical Signal Processing</dc:title>
          <dc:title xml:lang="deu">Unüberwachte Lernverfahren zur statistischen Signalverarbeitung</dc:title>
          <dc:creator>Vollgraf, Roland</dc:creator>
          <dc:subject>ddc:004</dc:subject>
          <dc:description xml:lang="eng">In many problems of Artificial Intelligence and Machine Learning, one makes use of statistical methods in order to extract relevant features and information from a given set of often numerical data. The approaches that come into consideration therefor always comprise two parts. At first, the given data have to be put into the context of a plausible statistical model, where the data must allow to empirically describe the model. Secondly, one has to find a suitable statistical method that allows to extract the desired features from the model, which is represented by the data. From this point of view, the title already make apparent that focus of this thesis is on methods that interpret given data as statistical signals or, in the terminology of probability theory, as stochastic processes, and that make use of statistical methods which belong to the family of unsupervised learning methods. The interpretation of a finite dataset as one or more realizations of a stochastic process in not stringent (and even sometimes inappropriate). In general the given dataset is multi-dimensional and of numerical nature or can be transformed that way. A quite simpler model could be achieved if all data along one dimension were interpreted as the realizations of a multi-variate random variable. This approach underlies many machine learning procedures like, e.g., Clustering, Principal Component Analysis, Projection Pursuit, or Independent Component Analysis (ICA) to name some representative unsupervised learning methods. However, even with ICA it becomes apparent where the model of a multi-variate random variable fails. Second Order Blind Source Separation can be considered as a counterpart to ICA. Both methods approach blind source separation and lead to a linear transformation of the underlying statistical model. However, while ICA can be derived solely from a multi-variate statistical distribution, Second Order BSS requires temporal' correlations or non-stationarities -- quantities that are not contained in the model of a multi-variate random variable, but are in the more general model of a stochastic process. This more general model can be seen as a thread through this thesis. Therefore, chapter 1 is devoted to the formal definition of stochastic processes and their important properties like stationarity and ergodicity. If one can find a plausible interpretation of a given dataset as a stochastic process, then immediately it becomes clear what is meant by the term statistical signal processing', namely any mapping that transforms one stochastic process into another one. In this respect one can distinguish supervised and unsupervised learning methods. Supervised learning methods are those for which with a realization of the one stochastic process (the given dataset), also a realization of the other stochastic process is available (a target dataset) such that a mapping from one process to the other is searched, that is consistent with both realizations and sufficiently general to be consistent with future realization of both stochastic processes. In contrast, in unsupervised learning methods a mapping is searched such that the resulting stochastic process exhibits certain statistical properties, which arise from the problem at hand. This thesis contains the results of my work on different problems in statistical data analysis. Due to the numerous collaborations that exist between the Neural Information Processing Group and many other labs, the data and the associated problems originate from quite different domains. Most of them were from the field of biomedical data analysis. Common to all is the fact that they fit well into the framework of stochastic processes. Except for section 4.3 all presented methods are unsupervised learning of signal processing mappings. According to their characteristics this thesis is organized into the chapters Instantaneous~Linear Functions, Optimal Linear Filters, Non-Linear Filtering, and Slow Feature Analysis as a general non-linear method. The individual chapters do not claim to be complete in terms of classes of signal processing methods they represent. Rather some individual procedures and results that are of particular interest shall be presented.</dc:description>
          <dc:description xml:lang="deu">In vielen Problemstellungen der Künstlichen Intelligenz und des Maschinellen Lernens bedient man sich statistischer Methoden, um aus einer gegeben Menge von oftmals numerischen Daten relevante Merkmale und Informationen zu extrahieren. Die dazu in Betracht kommenden Vorgehensweisen bestehen stets aus zwei Teilen. Zum Ersten sind die gegebenen Daten in den Kontext eines plausiblen statistischen Modells zu stellen, wobei die Daten eine empirische Beschreibung dieses Modells erlauben müssen. Zum Zweiten ist eine geeignete statistische Methode zu finden, die aus dem Modell, repräsentiert durch die Daten, die gewünschten Merkmale extrahieren kann. Unter diesem Gesichtspunkt wird aus dem Titel bereits klar, dass in der vorliegenden Arbeit der Schwerpunkt auf Verfahren liegt, die die gegeben Daten als statistische Signale oder, in der Terminologie der Wahrscheinlichkeitstheorie, als stochastische Prozesse interpretieren und dass die verwendeten statistischen Methoden zu den unüberwachten Lernverfahren zählen. Die Interpretation eines endlichen Datensatzes als eine oder mehrere Realisierungen eines stochastischen Prozesses ist durchaus nicht zwingend (und manchmal sogar unangebracht). In aller Regel ist der gegebene Datensatz mehrdimensional und numerischer Art oder lässt sich entsprechend umformen. Ein deutlich einfacheres statistisches Modell ergibt sich wenn man die Daten entlang einer Dimension als Realisierungen einer multivariaten Zufallsvariable auffasst. Dieser Ansatz liegt vielen maschinellen Lernverfahren zu Grunde, wie z.B. Clustering, Hauptkomponentenanalyse, Projection Pursuit oder Independent Component Analysis (ICA) als einige Vertreter unüberwachter Lernverfahren. Jedoch gerade am Beispiel von ICA lässt sich gut zeigen, wo das Modell einer multivariaten Zufallsvariable versagt. Als Gegenstück zu ICA kann man Second Order Blind Source Separation auffassen. Beide Methoden dienen der blinden Quellentrennung und resultieren in einer linearen Transformation des angenommenen statistischen Modells. Während sich jedoch ICA allein aus der Verteilung einer multivariaten Zufallsvariable ableiten lässt, benötigt man für Second Order BSS "zeitliche" Korrelationen oder Nichtstationaritäten -- Grössen die in dem Modell einer multivariaten Zufallsvariable nicht enthalten sind, wohl aber in dem generelleren Modell eines stochastischen Prozesses. Dieses generellere Modell kann als roter Faden durch die vorliegende Arbeit angesehen werden. Kapitel 1 widmet sich daher der formalen Definition stochastischer Prozesse und wichtigen Eigenschaften derselben wie z.B. Stationarität und Ergodizität. Kann man eine plausible Interpretation eines gegebenen Datensatzes als stochastischen Prozess finden, dann ist auch sofort klar, was unter statistischer Signalverarbeitung zu verstehen ist, nämlich eine jede Abbildung, die einen stochastischen Prozess in einen anderen überführt. Unter diesem Gesichtspunkt kann man überwachte und unüberwachte Lernverfahren unterscheiden. Überwachte sind solche, bei denen für eine Realisierung des einen Prozesses (der gegebene Datensatz) auch eine Realisierung des anderen verfügbar ist (Target-Datensatz), wobei eine Abbildung gesucht wird, die konsistent mit beiden Realisierungen ist, und die generell genug ist, um auch mit zukünftigen Realisierungen beider stochastischer Prozesse konsistent zu sein. Im Gegensatz dazu ist beim unüberwachten Lernen eine Abbildung gesucht, sodass der resultierende stochastische Prozess bestimmte statistische Eigenschaften aufweist, welche sich aus der Problemstellung ergeben. Die vorliegende Arbeit beinhaltet die Ergebnisse verschiedener Arbeiten zu Problemen der statistischen Datenanalyse. Aufgrund der zahlreichen Kooperationen, die zwischen der Arbeitsgruppe Neuronale Informationsverarbeitung'' und vielen anderen Arbeitsgruppen bestehen, stammen die Aufgaben aus zum Teil recht verschiedenen Domänen. Viele kamen dabei aus dem Gebiet der biomedizinischen Datananalyse. Allen gemein ist, dass die gegebenen Daten sehr gut zu den Modellen stochastischer Prozesse passten. Bis auf Abschnitt 4.3 handelt es sich bei den dargestellten Methoden um unüberwachtes Lernen von signalverarbeitenden Abbildungen. Deren Charakteristiken entsprechend ist die vorliegende Arbeit gegliedert in Instantane Lineare Funktionen, Optimale Lineare Filter, Nichtlineare Filter und Slow Feature Analyse als allgemeine nichtlineare Methode. Dabei erheben die einzelnen Kapitel keinen Anspruch auf Vollständigkeit bezüglich der dargestellten Klassen von Methoden. Vielmehr sollen einzelne, dafür aber besonders interessante Verfahren und Ergebnisse vorgestellt werden.</dc:description>
          <dc:date>2007-01-29</dc:date>
          <dc:type>doctoralthesis</dc:type>
          <dc:type>doc-type:doctoralthesis</dc:type>
          <dc:format>video/x-msvideo</dc:format>
          <dc:format>video/x-msvideo</dc:format>
          <dc:format>video/x-msvideo</dc:format>
          <dc:format>video/x-msvideo</dc:format>
          <dc:format>video/x-msvideo</dc:format>
          <dc:format>video/x-msvideo</dc:format>
          <dc:format>video/x-msvideo</dc:format>
          <dc:format>application/zip</dc:format>
          <dc:format>application/zip</dc:format>
          <dc:format>application/pdf</dc:format>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/frontdoor/index/index/docId/1432</dc:identifier>
          <dc:identifier>urn:nbn:de:kobv:83-opus-14886</dc:identifier>
          <dc:identifier>http://nbn-resolving.de/urn/resolver.pl?urn:nbn:de:kobv:83-opus-14886</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/original_filt_3_4_5_7_14.avi</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/original_filt_8_11_12.avi</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/original_floor_%2B2.avi</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/original_floor_-1.avi</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/original_res_floor_%2B2.avi</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/original_res_floor_-1.avi</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/original_video1.avi</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/original_videos.zip</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/videos.zip</dc:identifier>
          <dc:identifier>http://opus4.kobv.de/opus4-tuberlin/files/1432/vollgraf_roland.pdf</dc:identifier>
          <dc:language>eng</dc:language>
          <dc:rights>Deutsches Urheberrecht mit Print on Demand (u.a. für Dissertationen empfohlen)</dc:rights>
        </oai_dc:dc>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
